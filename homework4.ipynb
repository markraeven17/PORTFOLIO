{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.layers import Convolution2D, MaxPooling2D, Conv2DTranspose, Dropout,InputLayer, Flatten, Dense, BatchNormalization\n", "from keras.models import Sequential\n", "import numpy as np\n", "from keras.datasets import mnist\n", "from keras.datasets import fashion_mnist\n", "import matplotlib.pyplot as plt\n", "import matplotlib.image as mpimg\n", "from keras.utils import np_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(X_train, y_train), (X_test, y_test) = mnist.load_data()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def noise(array):\n", "    noise_factor = 0.4\n", "    noisy_array = array + noise_factor * np.random.normal(\n", "    loc=0.0, scale=1.0, size=array.shape)\n", "    return np.clip(noisy_array, 0.0, 1.0)   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["noisy_X_train = noise(X_train)\n", "noisy_X_test = noise(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 5  \n", "plt.figure(figsize=(10, 4))\n", "for i in range(n):\n", "    # Original\n", "    ax = plt.subplot(2, n, i + 1)\n", "    plt.imshow(X_train[i], cmap='gray')\n", "    plt.title(\"Original\")\n", "    plt.axis('off')\n\n", "    # Noisy\n", "    ax = plt.subplot(2, n, i + 1 + n)\n", "    plt.imshow(noisy_X_train[i], cmap='gray')\n", "    plt.title(\"Noisy\")\n", "    plt.axis('off')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X_train.astype('float32') / 255.\n", "X_test = X_test.astype('float32') / 255."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X_train.reshape(-1, 28, 28, 1)\n", "X_test = X_test.reshape(-1, 28, 28, 1)\n", "noisy_X_train = noisy_X_train.reshape(-1, 28, 28, 1)\n", "noisy_X_test = noisy_X_test.reshape(-1, 28, 28, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder = Sequential()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.add(InputLayer(input_shape=(28, 28, 1)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.add(Convolution2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n", "autoencoder.add(MaxPooling2D((2, 2), padding=\"same\"))\n", "autoencoder.add(Convolution2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n", "autoencoder.add(MaxPooling2D((2, 2), padding=\"same\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.add(Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"))\n", "autoencoder.add(Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"))\n", "autoencoder.add(Convolution2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.fit(noisy_X_train, X_train,\n", "                epochs=5,\n", "                batch_size=128,\n", "                validation_data=(noisy_X_test, X_test))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clean_images = autoencoder.predict(noisy_X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 10\n", "indices = np.random.randint(0, noisy_X_test.shape[0], size=n)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, idx in enumerate(indices):\n", "    ax = plt.subplot(3, n, i + 1)\n", "    plt.imshow(noisy_X_test[idx].reshape(28, 28), cmap='gray')\n", "    plt.title(\"Noisy\")\n", "    plt.axis('off')\n", "    ax = plt.subplot(3, n, i + 1 + n)\n", "    plt.imshow(clean_images[idx].reshape(28, 28), cmap='gray')\n", "    plt.title(\"Denoised\")\n", "    plt.axis('off')\n\n", "    # Ground truth (original image)\n", "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n", "    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n", "    plt.title(\"Original\")\n", "    plt.axis('off')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n", "imgplot = plt.imshow(X_train[3,:,:],cmap='viridis')\n", "plt.show()\n", "imgplot = plt.imshow(X_train[16,:,:],cmap='viridis')\n", "plt.show()\n", "imgplot = plt.imshow(X_train[1,:,:],cmap='plasma')\n", "plt.show()\n", "imgplot = plt.imshow(X_train[9,:,:],cmap='magma')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n", "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n", "X_train = X_train.astype('float32')\n", "X_test = X_test.astype('float32')\n", "X_train /= 255\n", "X_test /= 255\n", "y_train = np_utils.to_categorical(y_train, 10)\n", "y_test = np_utils.to_categorical(y_test, 10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Sequential()\n", "model.add(Convolution2D(64, (3, 3), activation='relu', input_shape=(28,28,1), padding=\"same\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(model.output_shape)\n", "model.add(Convolution2D(64, (3, 3), activation='relu', padding=\"same\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(model.output_shape)\n", "model.add(Convolution2D(64, (3, 3), activation='relu', padding=\"same\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(model.output_shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pooling Layer:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.add(MaxPooling2D(pool_size=(2,2)))\n", "print(model.output_shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dropout layer to avoid overfitting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.add(Dropout(0.5)) \n", "# output Fully connected Dense layers:\n", "model.add(Flatten())\n", "print(model.output_shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.add(Dense(256, activation='relu'))\n", "print(model.output_shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.add(Dropout(0.5))\n", "model.add(Dense(10, activation='softmax'))\n", "print(model.output_shape)\n", "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],\n", "              optimizer='RMSprop')\n", "# more info about loss functions: https://keras.io/losses\n", "# more infor about Optimizers: https://keras.io/optimizers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(model.summary())\n", "history = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split=0.2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy = history.history['accuracy']\n", "val_accuracy = history.history['val_accuracy']\n", "loss = history.history['loss']\n", "val_loss = history.history['val_loss']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = range(len(accuracy))\n", "plt.plot(epochs, accuracy, 'b-', label='Training accuracy')\n", "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n", "plt.title('Training and validation accuracy')\n", "plt.legend()\n", "plt.figure()\n", "plt.plot(epochs, loss, 'r-', label='Training loss')\n", "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n", "plt.title('Training and validation loss')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predicted_classes = model.predict(X_test)\n", "score = model.evaluate(X_test, y_test, verbose=1)\n", "print('The accuracy is: ', score[1])"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}